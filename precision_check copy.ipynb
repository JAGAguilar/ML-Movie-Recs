{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block One: First Filtering\n",
    "#reading the CSV files, change them on your personal computer to wherever you saved them\n",
    "rate = pd.read_csv(r'ml-latest/ratings.csv')\n",
    "movies = pd.read_csv(r'ml-latest/movies.csv')\n",
    "ratings = pd.read_csv(r'ml-latest/ratings.csv')\n",
    "tags = pd.read_csv(r'ml-latest/tags.csv')\n",
    "userID = ratings\n",
    "#dropping timestamp as it's unnecessary\n",
    "tags = tags.drop(columns='timestamp')\n",
    "ratings = ratings.drop(columns='timestamp') \n",
    "\n",
    "#Groups on userId and movieId and groups tags into a list\n",
    "tags = tags.groupby(['movieId']).agg({'tag':set}).reset_index()\n",
    "\n",
    "#Refining ratings to just be movieId and the average rating to only 1 decimal point\n",
    "ratings = ratings.groupby('movieId')['rating'].mean().reset_index()\n",
    "ratings = ratings.rename(columns={'rating':'average_rating'})\n",
    "ratings['average_rating'] = ratings['average_rating'].round(1)\n",
    "filtered_data = pd.merge(movies,ratings, on='movieId')\n",
    "filtered_data = pd.merge(filtered_data, tags, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#Block Two: Unique Genres and Second Filtering\n",
    "# Split genres by '|' and get all unique genres\n",
    "unique_genres = set()\n",
    "for genres in movies['genres']:\n",
    "    unique_genres.update(genres.split('|'))\n",
    "unique_genres = sorted(unique_genres)  # Sort in alphabetic order\n",
    "print(len(unique_genres))\n",
    "for genre in unique_genres:\n",
    "    filtered_data[genre] = filtered_data['genres'].apply(lambda x: 1 if genre in x.split('|') else 0)\n",
    "#filter out In Netflix Queue\n",
    "filtered_data['tag'] = filtered_data['tag'].apply(lambda tag_set: {tag for tag in tag_set if tag != \"In Netflix queue\"})\n",
    "# print(filtered_data.head())\n",
    "\n",
    "# Drop the original 'genres' column (I think it's a good idea, no need to clutter the data yk?)\n",
    "filtered_data= filtered_data.drop(columns=['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block Three: Vectorization\n",
    "#I changed the vector size to 10 just cause it's smaller but if you wanna increase it by all means go for it\n",
    "wordVector = Word2Vec(filtered_data['tag'].tolist(),vector_size=10, window=5, min_count=1, workers=4)\n",
    "\n",
    "vector_size = 10  # Same size as Word2Vec vectors\n",
    "padding_vector = np.zeros(vector_size)\n",
    "# Function to generate a vector for up to 3 tags\n",
    "def create_feature_vector(row):\n",
    "    # Get word vectors for the tags, up to 3 tags, and pad if fewer\n",
    "    tag_vectors = [\n",
    "        wordVector.wv[tag] if tag in wordVector.wv else padding_vector\n",
    "        for tag in list(row['tag'])[:3] # inlude if needed\n",
    "    ]\n",
    "    while len(tag_vectors) < 3:  # Pad with zero vectors if fewer than 3 tags\n",
    "        tag_vectors.append(padding_vector)\n",
    "    \n",
    "    # Flatten the tag vectors (3 vectors of size 10 each -> 30 elements)\n",
    "    tag_vector = np.concatenate(tag_vectors)\n",
    "    \n",
    "    # Add genre one-hot encoding\n",
    "    genre_vector = row[unique_genres].values  # One-hot encoded genres\n",
    "    \n",
    "    # Combine tag vector and genre vector\n",
    "    feature_vector = np.concatenate([tag_vector, genre_vector])\n",
    "    return feature_vector\n",
    "\n",
    "#wrote to file to see feature data\n",
    "# filtered_data.to_csv('filtered_movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------This is genre-vec len: 20 --------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv('ml-latest/movies.csv')\n",
    "tags_df = pd.read_csv('ml-latest/tags.csv')\n",
    "tags_set = tags_df.groupby(['movieId']).agg({'tag':set}).reset_index()\n",
    "\n",
    "\"\"\"      Genres_vector     \"\"\"\n",
    "# Initialize the genre_vector list\n",
    "genre_vector = []\n",
    "\n",
    "# Iterate over each movie's genres\n",
    "for _, row in movies_df.iterrows():\n",
    "    # Create a one-hot vector for the current movie\n",
    "    genres = row['genres'].split('|')\n",
    "    vector = [1 if genre in genres else 0 for genre in unique_genres]\n",
    "    genre_vector.append(vector)\n",
    "\n",
    "# Convert to a numpy array for further use\n",
    "genre_vector = np.array(genre_vector)\n",
    "\n",
    "# Add the genre_vector to the dataframe for reference (optional)\n",
    "movies_df['genre_vector'] = list(genre_vector)\n",
    "print(f\"\\n ------This is genre-vec len: {len(movies_df['genre_vector'][0])} --------- \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------This is movie-vec len: 20 --------- \n",
      "\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \\\n",
      "0  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "1                   Adventure|Children|Fantasy   \n",
      "2                               Comedy|Romance   \n",
      "3                         Comedy|Drama|Romance   \n",
      "4                                       Comedy   \n",
      "\n",
      "                                        genre_vector  \\\n",
      "0  [0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
      "2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                                 tag  \\\n",
      "0  {buzz lightyear character, ventilation shaft, ...   \n",
      "1  {classic, based on novel, beat up, cracked win...   \n",
      "2  {duringcreditsstinger, fishing, moldy, Daryl H...   \n",
      "3  {CLV, based on novel or book, slurs, girl movi...   \n",
      "4  {Fantasy, Touching, contraception, regret, Ste...   \n",
      "\n",
      "                                            tag_list  \\\n",
      "0  [buzz lightyear character, ventilation shaft, ...   \n",
      "1  [classic, based on novel, beat up, cracked win...   \n",
      "2  [duringcreditsstinger, fishing, moldy, daryl h...   \n",
      "3  [clv, based on novel or book, slurs, girl movi...   \n",
      "4  [fantasy, touching, contraception, regret, ste...   \n",
      "\n",
      "                                          tag_vector  \n",
      "0  [-0.043823928, -0.10386305, -0.20415013, 0.254...  \n",
      "1  [-0.027821925, -0.1709766, -0.39386553, 0.3999...  \n",
      "2  [-0.29177186, 0.08404679, 0.043962542, 0.25392...  \n",
      "3  [-1.1505054, 0.8926495, -0.09852208, 1.4232724...  \n",
      "4  [-0.43489224, 0.49144214, -0.7246201, 0.867120...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"       Tags_vector      \"\"\"\n",
    "# Merge tags with movies, ensuring all movies are included\n",
    "movies_df = movies_df.merge(tags_set, how='left', on='movieId')\n",
    "\n",
    "# Replace NaN tags with an empty set\n",
    "movies_df['tag'] = movies_df['tag'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "\n",
    "# Check unique data types in 'tag' for debugging (optional)\n",
    "# print(movies_df['tag'].apply(type).value_counts())\n",
    "\n",
    "# Preprocess tags: Split, clean, and ensure consistency\n",
    "def preprocess_tags(tag_set):\n",
    "    \"\"\"\n",
    "    Process a set of tags by stripping and converting them to lowercase.\n",
    "    Handles empty sets gracefully.\n",
    "    \"\"\"\n",
    "    if isinstance(tag_set, set):\n",
    "        return [str(tag).strip().lower() for tag in tag_set if isinstance(tag, str)]\n",
    "    return []\n",
    "\n",
    "movies_df['tag_list'] = movies_df['tag'].apply(preprocess_tags)\n",
    "\n",
    "# 3. Train word2vec model\n",
    "# Combine all tag lists into one list of lists\n",
    "tag_corpus = movies_df['tag_list'].tolist()\n",
    "\n",
    "# Train a word2vec model\n",
    "word2vec_model = Word2Vec(tag_corpus, vector_size=20, window=5, min_count=1, workers=4)\n",
    "\n",
    "# 4. Create movie vectors by averaging tag vectors\n",
    "def get_movie_vector(tags):\n",
    "    tag_vectors = [word2vec_model.wv[tag] for tag in tags if tag in word2vec_model.wv]\n",
    "    return np.mean(tag_vectors, axis=0) if tag_vectors else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "movies_df['tag_vector'] = movies_df['tag_list'].apply(get_movie_vector)\n",
    "print(f\"\\n ------This is movie-vec len: {len(movies_df['tag_vector'][0])} --------- \\n\")\n",
    "\n",
    "# 5. Drop unnecessary columns if needed\n",
    "# movies_df = movies_df.drop(columns=['tags', 'tag_list'])\n",
    "\n",
    "print(movies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "   movieId                               title  average_rating  \\\n",
      "0        1                    Toy Story (1995)             3.9   \n",
      "1        2                      Jumanji (1995)             3.3   \n",
      "2        3             Grumpier Old Men (1995)             3.2   \n",
      "3        4            Waiting to Exhale (1995)             2.9   \n",
      "4        5  Father of the Bride Part II (1995)             3.1   \n",
      "\n",
      "                                      feature_vector  \n",
      "0  [-0.04382392764091492, -0.10386305302381516, -...  \n",
      "1  [-0.027821924537420273, -0.17097659409046173, ...  \n",
      "2  [-0.29177185893058777, 0.08404678851366043, 0....  \n",
      "3  [-1.1505054235458374, 0.8926494717597961, -0.0...  \n",
      "4  [-0.4348922371864319, 0.49144214391708374, -0....  \n"
     ]
    }
   ],
   "source": [
    "filtered_data_copy = filtered_data.copy()\n",
    "\n",
    "# What we used before\n",
    "# filtered_data['feature_vector'] = filtered_data.apply(create_feature_vector, axis=1)\n",
    "\n",
    "# What we are using now\n",
    "movies_df['feature_vector'] = movies_df.apply(\n",
    "    lambda row: np.concatenate([row['tag_vector'], row['genre_vector']]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "filtered_data1 = filtered_data_copy.merge(\n",
    "    movies_df[['movieId', 'feature_vector']],  # Select only necessary columns\n",
    "    on='movieId',  # Merge on the 'movieId' column\n",
    "    how='left'  # Use a left join to keep all rows in filtered_data_df\n",
    ")\n",
    "\n",
    "#Okay so I mixed the tag vector and the genre vectors into one feature vector\n",
    "#I am going to drop the original tag vector and the genres\n",
    "filtered_data = filtered_data.drop(columns=list(unique_genres))\n",
    "filtered_data = filtered_data.drop(columns='tag')\n",
    "\n",
    "filtered_data1 = filtered_data1.drop(columns=list(unique_genres))\n",
    "filtered_data1 = filtered_data1.drop(columns='tag')\n",
    "\n",
    "print(len(filtered_data1['feature_vector'][6]))\n",
    "print(filtered_data1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query is the movie we want to isolate\n",
    "#Cosine Similarities\n",
    "def knn_recommendation_cos(query,train_data, user_watched_movies, k=5):\n",
    "    #Extract ratings and feature vectors from training set\n",
    "    #Ratings are optional if you don't want them, I have them here to use as bias\n",
    "    train_features = np.array(train_data['feature_vector'].tolist())\n",
    "    train_ratings = train_data['average_rating'].values#Optional\n",
    "\n",
    "    #kNN using cosine_similarity\n",
    "    similarities = cosine_similarity([query],train_features).flatten()\n",
    "\n",
    "    #Optional Bias\n",
    "    weighted_similarities = similarities * train_ratings\n",
    "\n",
    "    # #get the indicies of nearest movies (5)\n",
    "    # kNN_indices = np.argsort(weighted_similarities)[-k:][::-1] #Sorted by weighted similariy in descending order\n",
    "\n",
    "    # #Get the movies from the index\n",
    "    # kNN_movies = train_data.iloc[kNN_indices]\n",
    "        # Get the indices of nearest movies (more than k initially)\n",
    "    kNN_indices = np.argsort(weighted_similarities)[-k*2:][::-1]  # Get twice the number of recommendations (more than needed)\n",
    "\n",
    "    # Get the movies from the index\n",
    "    kNN_movies = train_data.iloc[kNN_indices]\n",
    "\n",
    "    # Remove the movies the user has already watched\n",
    "    kNN_movies_filtered = kNN_movies[~kNN_movies['movieId'].isin(user_watched_movies)]\n",
    "\n",
    "    # If we have fewer than k movies after filtering, fetch more from the remaining pool\n",
    "    if len(kNN_movies_filtered) < k:\n",
    "        # Find additional movies (not already recommended) by getting the remaining top recommendations\n",
    "        remaining_movies = kNN_movies[~kNN_movies['movieId'].isin(kNN_movies_filtered['movieId'])]\n",
    "        additional_movies_needed = k - len(kNN_movies_filtered)\n",
    "        additional_movies = remaining_movies.head(additional_movies_needed)\n",
    "        \n",
    "        # Combine the filtered list and additional recommendations\n",
    "        kNN_movies_filtered = pd.concat([kNN_movies_filtered, additional_movies])\n",
    "\n",
    "    return kNN_movies_filtered.head(k)  # Ensure we return exactly k recommendations\n",
    "    # return kNN_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to compare cosine to euclidean distance\n",
    "def knn_recommendation_eucl(query,train_data,k=5):\n",
    "    #Extract ratings and feature vectors from training set\n",
    "    #Ratings are optional if you don't want them, I have them here to use as bias\n",
    "    train_features = np.array(train_data['feature_vector'].tolist())\n",
    "    train_ratings = train_data['average_rating'].values#Optional\n",
    "\n",
    "    #kNN using euclidean distances\n",
    "    distances = euclidean_distances([query],train_features).flatten()\n",
    "\n",
    "    #Optional Bias\n",
    "    weighted_distances= distances / train_ratings\n",
    "\n",
    "    #get the indicies of nearest movies (5)\n",
    "    kNN_indices = np.argsort(weighted_distances)[:k] #Sorted by weighted distances ascending order\n",
    "\n",
    "    #Get the movies from the index\n",
    "    kNN_movies = train_data.iloc[kNN_indices]\n",
    "    return kNN_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_knn(test_data,train_data,user_watched_movies, k=5):\n",
    "    # Dictionary to store movie frequencies\n",
    "    movie_frequency = {}\n",
    "\n",
    "    for _,row in test_data.iterrows():\n",
    "        query = np.array(row['feature_vector'])\n",
    "        knn_movies = knn_recommendation_cos(query,train_data,user_watched_movies,k)\n",
    "        # print(f\"Current Movie searched: {row['title']}\")\n",
    "        # print(\"Recommended Movies: \")\n",
    "        # print(knn_movies[['title','average_rating']])\n",
    "        # print()\n",
    "\n",
    "        # Update the frequency dictionary\n",
    "        for _, movie_row in knn_movies.iterrows():\n",
    "            movie_title = movie_row['title']\n",
    "            movie_id = movie_row['movieId']\n",
    "            if movie_title in movie_frequency:\n",
    "                movie_frequency[movie_title][0] += 1\n",
    "            else:\n",
    "                movie_frequency[movie_title] = [1, movie_id]\n",
    "\n",
    "    # Sort the movie_frequency dictionary by frequency (the first element of the list)\n",
    "    sorted_dict = dict(sorted(movie_frequency.items(), key=lambda item: item[1][0], reverse=True))\n",
    "\n",
    "    # Get the movie with the maximum frequency\n",
    "    max_key = max(movie_frequency, key=lambda k: movie_frequency[k][0])  # Get the movie with the highest frequency\n",
    "    max_value = movie_frequency[max_key]  # The value is a list: [frequency, movie_id]\n",
    "\n",
    "    print(f\"Maximum value: {max_value[0]} with Key: {max_key} and Movie ID: {max_value[1]}\")\n",
    "\n",
    "    # Print the top 5 recommended movies\n",
    "    count = 0\n",
    "    movieIds = []\n",
    "    for movie, freq in sorted_dict.items():\n",
    "        print(f\"{movie}: Frequency = {freq[0]}, Movie ID = {freq[1]}\")  # Display frequency and Movie ID\n",
    "        movieIds.append(freq[1])\n",
    "        if count == 5:\n",
    "            break\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "    \n",
    "    return movieIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(movie_id_1, movie_id_2, train_data):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two movies based on their feature vectors.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the feature vectors for the two movies\n",
    "    movie_1_vector = train_data.loc[train_data['movieId'] == movie_id_1, 'feature_vector'].values[0]\n",
    "    # print(movie_1_vector)\n",
    "    movie_2_vector = train_data.loc[train_data['movieId'] == movie_id_2, 'feature_vector'].values[0]\n",
    "\n",
    "    # Reshape the vectors to 2D arrays (required for cosine_similarity)\n",
    "    movie_1_vector = movie_1_vector.reshape(1, -1)\n",
    "    movie_2_vector = movie_2_vector.reshape(1, -1)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(movie_1_vector, movie_2_vector)[0][0]\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(df, filt_data, n=7):\n",
    "    # Create empty lists to store train and test data\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # Group by 'userID' to process each user individually\n",
    "    \n",
    "    merged_df = pd.merge(df, filt_data, on='movieId')\n",
    "    grouped = merged_df.groupby('userId')\n",
    "\n",
    "    for user, group in grouped:\n",
    "        # Sort movies by rating in descending order\n",
    "        sorted_group = group.sort_values(by='rating', ascending=False)\n",
    "        \n",
    "        # Select the top n rated movies for testing\n",
    "        test = sorted_group.head(n)\n",
    "        \n",
    "        # Use the rest for training\n",
    "        train = sorted_group.iloc[n:]\n",
    "        \n",
    "        # Append to respective lists\n",
    "        test_list.append(test)\n",
    "        train_list.append(train)\n",
    "\n",
    "    # Combine all train and test splits into DataFrames\n",
    "    train_data = pd.concat(train_list).reset_index(drop=True)\n",
    "    test_data = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    print(\"Training Data:\")\n",
    "    print(train_data)\n",
    "    print(\"\\nTesting Data:\")\n",
    "    print(test_data)\n",
    "    print(type(train_data))\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "          userId  movieId  rating   timestamp  \\\n",
      "0              1     4995     5.0  1225734583   \n",
      "1              1     7153     5.0  1225735149   \n",
      "2              1     1291     5.0  1225734809   \n",
      "3              1     8533     5.0  1225737239   \n",
      "4              1     3578     5.0  1225735309   \n",
      "...          ...      ...     ...         ...   \n",
      "32099713  330975      160     0.5  1091583193   \n",
      "32099714  330975     2792     0.5  1091582197   \n",
      "32099715  330975     2953     0.5  1091582192   \n",
      "32099716  330975     1681     0.5  1091582912   \n",
      "32099717  330975      688     0.5  1091582787   \n",
      "\n",
      "                                                      title  average_rating  \\\n",
      "0                                  Beautiful Mind, A (2001)             4.0   \n",
      "1         Lord of the Rings: The Return of the King, The...             4.1   \n",
      "2                 Indiana Jones and the Last Crusade (1989)             4.0   \n",
      "3                                      Notebook, The (2004)             3.7   \n",
      "4                                          Gladiator (2000)             4.0   \n",
      "...                                                     ...             ...   \n",
      "32099713                                       Congo (1995)             2.6   \n",
      "32099714                     Airplane II: The Sequel (1982)             3.1   \n",
      "32099715              Home Alone 2: Lost in New York (1992)             2.7   \n",
      "32099716                 Mortal Kombat: Annihilation (1997)             2.1   \n",
      "32099717                        Operation Dumbo Drop (1995)             2.6   \n",
      "\n",
      "                                             feature_vector  \n",
      "0         [-0.3677230775356293, 0.24976098537445068, -0....  \n",
      "1         [0.049616262316703796, -0.13803158700466156, -...  \n",
      "2         [-0.05247368663549423, -0.09007574617862701, -...  \n",
      "3         [-0.23491767048835754, 0.009638983756303787, 0...  \n",
      "4         [-0.19444920122623444, -0.04494374617934227, 0...  \n",
      "...                                                     ...  \n",
      "32099713  [-0.10354123264551163, 0.18109412491321564, -0...  \n",
      "32099714  [0.0005594015237875283, -0.30875828862190247, ...  \n",
      "32099715  [0.01777474954724312, -0.07141365855932236, -0...  \n",
      "32099716  [-0.012180423364043236, -0.3532838523387909, 0...  \n",
      "32099717  [-0.9582516551017761, 0.5439802408218384, -0.9...  \n",
      "\n",
      "[32099718 rows x 7 columns]\n",
      "\n",
      "Testing Data:\n",
      "         userId  movieId  rating   timestamp  \\\n",
      "0             1     8132     5.0  1225865124   \n",
      "1             1    33166     5.0  1225735916   \n",
      "2             1     2762     5.0  1225735017   \n",
      "3             1     4886     5.0  1225734829   \n",
      "4             1     2028     5.0  1225735007   \n",
      "...         ...      ...     ...         ...   \n",
      "1588933  330975      912     5.0  1091584730   \n",
      "1588934  330975     1221     4.0  1091582131   \n",
      "1588935  330975     3996     4.0  1091585028   \n",
      "1588936  330975      923     4.0  1091585099   \n",
      "1588937  330975     6299     4.0  1091684224   \n",
      "\n",
      "                                                     title  average_rating  \\\n",
      "0                                         Gladiator (1992)             3.9   \n",
      "1                                             Crash (2004)             3.7   \n",
      "2                                  Sixth Sense, The (1999)             4.0   \n",
      "3                                    Monsters, Inc. (2001)             3.8   \n",
      "4                               Saving Private Ryan (1998)             4.1   \n",
      "...                                                    ...             ...   \n",
      "1588933                                  Casablanca (1942)             4.2   \n",
      "1588934                     Godfather: Part II, The (1974)             4.3   \n",
      "1588935  Crouching Tiger, Hidden Dragon (Wo hu cang lon...             3.8   \n",
      "1588936                                Citizen Kane (1941)             4.1   \n",
      "1588937     Winged Migration (Peuple migrateur, Le) (2001)             3.9   \n",
      "\n",
      "                                            feature_vector  \n",
      "0        [-0.25075191259384155, -0.04785878211259842, 0...  \n",
      "1        [-0.16531819105148315, -0.13477423787117004, -...  \n",
      "2        [-0.07960520684719086, -0.16352282464504242, -...  \n",
      "3        [-0.05253826826810837, 0.06909201294183731, -0...  \n",
      "4        [-0.1635509580373764, -0.08266964554786682, -0...  \n",
      "...                                                    ...  \n",
      "1588933  [-0.28220561146736145, 0.21358095109462738, -0...  \n",
      "1588934  [-0.12399005144834518, -0.03637717291712761, -...  \n",
      "1588935  [-0.1059468537569046, -0.026344064623117447, 0...  \n",
      "1588936  [0.02247020974755287, -0.03785650432109833, -0...  \n",
      "1588937  [-0.11587091535329819, 0.4866465926170349, 0.1...  \n",
      "\n",
      "[1588938 rows x 7 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# train_data, test_data = my_train_test_split(rate, filtered_data,n=0)\n",
    "train_data1, test_data1 = my_train_test_split(rate, filtered_data1,n=5)\n",
    "\n",
    "# print(f\"traing_data query{len(train_data['feature_vector'][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for that specific user\n",
    "# print(type(train_data))\n",
    "# print(train_data)\n",
    "user_id = 10\n",
    "# user_data = train_data[train_data['userId'] == user_id]\n",
    "user_data1 = train_data1[train_data1['userId'] == user_id]\n",
    "# user_data1 = test_data[test_data['userId'] == 2]\n",
    "# print(user_data)\n",
    "# print(user_data1)\n",
    "\n",
    "# test_knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value: 70 with Key: In Her Line of Fire (2006) and Movie ID: 159053\n",
      "In Her Line of Fire (2006): Frequency = 70, Movie ID = 159053\n",
      "WWE: The Triumph and Tragedy of World Class Championship Wrestling (2007): Frequency = 69, Movie ID = 270306\n",
      "Beyond Words (2018): Frequency = 56, Movie ID = 275847\n",
      "The Blair Thumb (2002): Frequency = 54, Movie ID = 176719\n",
      "Hercules vs. the Giant Warriors (1964): Frequency = 45, Movie ID = 148126\n",
      "Churuli (2021): Frequency = 43, Movie ID = 280184\n",
      "\n",
      " ---------- Next old Filter --------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_watched_movies = user_data1['movieId'].to_numpy()\n",
    "# print(user_watched_movies)\n",
    "# you can use either filtered_data1(new vect) or filtered_data(old vect)\n",
    "movieIDs1 = test_knn(user_data1, filtered_data1, user_watched_movies, k=5)\n",
    "\n",
    "print(\"\\n ---------- Next old Filter --------- \\n\")\n",
    "\n",
    "# movieIDs = test_knn(user_data, filtered_data, user_watched_movies, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "Recommended movie: In Her Line of Fire (2006): ID(159053), Similarity:0.843565092856572\n",
      "Recommended movie: WWE: The Triumph and Tragedy of World Class Championship Wrestling (2007): ID(270306), Similarity:0.8452535784023585\n",
      "Recommended movie: Beyond Words (2018): ID(275847), Similarity:0.8459261775768931\n",
      "Recommended movie: The Blair Thumb (2002): ID(176719), Similarity:0.8471252797125722\n",
      "Recommended movie: Hercules vs. the Giant Warriors (1964): ID(148126), Similarity:0.8382088325348092\n",
      "Recommended movie: Churuli (2021): ID(280184), Similarity:0.837247686966817\n"
     ]
    }
   ],
   "source": [
    "user_test_movies = user_data1['movieId'].to_numpy()\n",
    "print(len(user_test_movies))\n",
    "arr = []\n",
    "\n",
    "for x in movieIDs1:\n",
    "    arr = []\n",
    "    for y in user_test_movies:\n",
    "        z = calculate_cosine_similarity(x, y, filtered_data1)\n",
    "        arr.append(z)\n",
    "\n",
    "    print(f\"Recommended movie: {filtered_data1.loc[filtered_data1['movieId'] == x].iloc[0]['title']}: ID({x}), Similarity:{np.mean(arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "Recommended movie: 6201 Similarity:0.3923577293777858\n",
      "Recommended movie: 7023 Similarity:0.4350625505718232\n",
      "Recommended movie: 898 Similarity:0.4487964942409145\n",
      "Recommended movie: 1235 Similarity:0.45537037418930904\n",
      "Recommended movie: 1277 Similarity:0.45984977370461944\n",
      "Recommended movie: 5404 Similarity:0.44869870955087665\n"
     ]
    }
   ],
   "source": [
    "user_test_movies = user_data['movieId'].to_numpy()\n",
    "print(len(user_test_movies))\n",
    "arr = []\n",
    "\n",
    "for x in movieIDs:\n",
    "    for y in user_test_movies:\n",
    "        z = calculate_cosine_similarity(x, y, filtered_data)\n",
    "        arr.append(z)\n",
    "\n",
    "    print(f\"Recommended movie: {x} Similarity:{np.mean(arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movie: In Her Line of Fire (2006): ID(159053), Similarity:0.8752660259925227\n",
      "Recommended movie: WWE: The Triumph and Tragedy of World Class Championship Wrestling (2007): ID(270306), Similarity:0.8727028158096571\n",
      "Recommended movie: Beyond Words (2018): ID(275847), Similarity:0.8449013872839813\n",
      "Recommended movie: The Blair Thumb (2002): ID(176719), Similarity:0.824579934833095\n",
      "Recommended movie: Hercules vs. the Giant Warriors (1964): ID(148126), Similarity:0.755566746481805\n",
      "Recommended movie: Churuli (2021): ID(280184), Similarity:0.8450899589814576\n",
      "unrelatedMovie ID 589: 0.6844338876287877\n"
     ]
    }
   ],
   "source": [
    "user_data2 = test_data1[test_data1['userId'] == 10]['movieId'].to_numpy()\n",
    "arr = []\n",
    "\n",
    "for x in movieIDs1:\n",
    "    arr = []\n",
    "    for y in user_data2:\n",
    "        z = calculate_cosine_similarity(x, y, filtered_data1)\n",
    "        arr.append(z)\n",
    "\n",
    "    print(f\"Recommended movie: {filtered_data1.loc[filtered_data1['movieId'] == x].iloc[0]['title']}: ID({x}), Similarity:{np.mean(arr)}\")\n",
    "\n",
    "print(f\"unrelatedMovie ID 589: {calculate_cosine_similarity(273,258, filtered_data1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
