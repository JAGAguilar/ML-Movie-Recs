{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block One: First Filtering\n",
    "#reading the CSV files, change them on your personal computer to wherever you saved them\n",
    "rate = pd.read_csv(r'ml-latest-small/ratings.csv')\n",
    "movies = pd.read_csv(r'ml-latest-small/movies.csv')\n",
    "ratings = pd.read_csv(r'ml-latest-small/ratings.csv')\n",
    "tags = pd.read_csv(r'ml-latest-small/tags.csv')\n",
    "userID = ratings\n",
    "#dropping timestamp as it's unnecessary\n",
    "tags = tags.drop(columns='timestamp')\n",
    "ratings = ratings.drop(columns='timestamp') \n",
    "\n",
    "#Groups on userId and movieId and groups tags into a list\n",
    "tags = tags.groupby(['movieId']).agg({'tag':set}).reset_index()\n",
    "\n",
    "#Refining ratings to just be movieId and the average rating to only 1 decimal point\n",
    "ratings = ratings.groupby('movieId')['rating'].mean().reset_index()\n",
    "ratings = ratings.rename(columns={'rating':'average_rating'})\n",
    "ratings['average_rating'] = ratings['average_rating'].round(1)\n",
    "filtered_data = pd.merge(movies,ratings, on='movieId')\n",
    "filtered_data = pd.merge(filtered_data, tags, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#Block Two: Unique Genres and Second Filtering\n",
    "# Split genres by '|' and get all unique genres\n",
    "unique_genres = set()\n",
    "for genres in movies['genres']:\n",
    "    unique_genres.update(genres.split('|'))\n",
    "unique_genres = sorted(unique_genres)  # Sort in alphabetic order\n",
    "print(len(unique_genres))\n",
    "for genre in unique_genres:\n",
    "    filtered_data[genre] = filtered_data['genres'].apply(lambda x: 1 if genre in x.split('|') else 0)\n",
    "#filter out In Netflix Queue\n",
    "filtered_data['tag'] = filtered_data['tag'].apply(lambda tag_set: {tag for tag in tag_set if tag != \"In Netflix queue\"})\n",
    "# print(filtered_data.head())\n",
    "\n",
    "# Drop the original 'genres' column (I think it's a good idea, no need to clutter the data yk?)\n",
    "filtered_data= filtered_data.drop(columns=['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block Three: Vectorization\n",
    "#I changed the vector size to 10 just cause it's smaller but if you wanna increase it by all means go for it\n",
    "wordVector = Word2Vec(filtered_data['tag'].tolist(),vector_size=10, window=5, min_count=1, workers=4)\n",
    "\n",
    "vector_size = 10  # Same size as Word2Vec vectors\n",
    "padding_vector = np.zeros(vector_size)\n",
    "# Function to generate a vector for up to 3 tags\n",
    "def create_feature_vector(row):\n",
    "    # Get word vectors for the tags, up to 3 tags, and pad if fewer\n",
    "    tag_vectors = [\n",
    "        wordVector.wv[tag] if tag in wordVector.wv else padding_vector\n",
    "        for tag in list(row['tag'])[:3] # inlude if needed\n",
    "    ]\n",
    "    while len(tag_vectors) < 3:  # Pad with zero vectors if fewer than 3 tags\n",
    "        tag_vectors.append(padding_vector)\n",
    "    \n",
    "    # Flatten the tag vectors (3 vectors of size 10 each -> 30 elements)\n",
    "    tag_vector = np.concatenate(tag_vectors)\n",
    "    \n",
    "    # Add genre one-hot encoding\n",
    "    genre_vector = row[unique_genres].values  # One-hot encoded genres\n",
    "    \n",
    "    # Combine tag vector and genre vector\n",
    "    feature_vector = np.concatenate([tag_vector, genre_vector])\n",
    "    return feature_vector\n",
    "\n",
    "#wrote to file to see feature data\n",
    "# filtered_data.to_csv('filtered_movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \\\n",
      "0  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "1                   Adventure|Children|Fantasy   \n",
      "2                               Comedy|Romance   \n",
      "3                         Comedy|Drama|Romance   \n",
      "4                                       Comedy   \n",
      "\n",
      "                                        genre_vector  \\\n",
      "0  [0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
      "2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                                 tag  \\\n",
      "0                                       {pixar, fun}   \n",
      "1  {magic board game, Robin Williams, fantasy, game}   \n",
      "2                                       {old, moldy}   \n",
      "3                                                 {}   \n",
      "4                                {remake, pregnancy}   \n",
      "\n",
      "                                            tag_list  \\\n",
      "0                                       [pixar, fun]   \n",
      "1  [magic board game, robin williams, fantasy, game]   \n",
      "2                                       [old, moldy]   \n",
      "3                                                 []   \n",
      "4                                [remake, pregnancy]   \n",
      "\n",
      "                                          tag_vector  \n",
      "0  [-0.0429442, -0.009570188, 0.008164824, 0.0407...  \n",
      "1  [-0.00057393126, 0.024589822, 0.00010280125, 0...  \n",
      "2  [0.032066673, -0.00062654726, -0.017126054, -0...  \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "4  [-0.013254916, 0.037702855, 0.004726384, 0.015...  \n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv('ml-latest-small/movies.csv')\n",
    "tags_df = pd.read_csv('ml-latest-small/tags.csv')\n",
    "tags_set = tags_df.groupby(['movieId']).agg({'tag':set}).reset_index()\n",
    "\n",
    "\"\"\"      Genres_vector     \"\"\"\n",
    "# Initialize the genre_vector list\n",
    "genre_vector = []\n",
    "\n",
    "# Iterate over each movie's genres\n",
    "for _, row in movies_df.iterrows():\n",
    "    # Create a one-hot vector for the current movie\n",
    "    genres = row['genres'].split('|')\n",
    "    vector = [1 if genre in genres else 0 for genre in unique_genres]\n",
    "    genre_vector.append(vector)\n",
    "\n",
    "# Convert to a numpy array for further use\n",
    "genre_vector = np.array(genre_vector)\n",
    "\n",
    "# Add the genre_vector to the dataframe for reference (optional)\n",
    "movies_df['genre_vector'] = list(genre_vector)\n",
    "# print(f\"\\n ------This is genre-vec len: {len(movies_df['genre_vector'][0])} --------- \\n\")\n",
    "\n",
    "\n",
    "\"\"\"       Tags_vector      \"\"\"\n",
    "# 3. Merge tags with movies, ensuring all movies are included\n",
    "movies_df = movies_df.merge(tags_set, how='left', left_on='movieId', right_on='movieId')\n",
    "\n",
    "# 4. Replace NaN tags with an empty set\n",
    "movies_df['tag'] = movies_df['tag'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "\n",
    "# 5. Preprocess tags: Split and clean\n",
    "movies_df['tag_list'] = movies_df['tag'].apply(lambda x: [tag.strip().lower() for tag in x])\n",
    "\n",
    "# 3. Train word2vec model\n",
    "# Combine all tag lists into one list of lists\n",
    "tag_corpus = movies_df['tag_list'].tolist()\n",
    "\n",
    "# Train a word2vec model\n",
    "word2vec_model = Word2Vec(tag_corpus, vector_size=20, window=5, min_count=1, workers=4)\n",
    "\n",
    "# 4. Create movie vectors by averaging tag vectors\n",
    "def get_movie_vector(tags):\n",
    "    tag_vectors = [word2vec_model.wv[tag] for tag in tags if tag in word2vec_model.wv]\n",
    "    return np.mean(tag_vectors, axis=0) if tag_vectors else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "movies_df['tag_vector'] = movies_df['tag_list'].apply(get_movie_vector)\n",
    "# print(f\"\\n ------This is movie-vec len: {len(movies_df['tag_vector'][0])} --------- \\n\")\n",
    "\n",
    "# 5. Drop unnecessary columns if needed\n",
    "# movies_df = movies_df.drop(columns=['tags', 'tag_list'])\n",
    "\n",
    "print(movies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "   movieId                               title  average_rating  \\\n",
      "0        1                    Toy Story (1995)             3.9   \n",
      "1        2                      Jumanji (1995)             3.4   \n",
      "2        3             Grumpier Old Men (1995)             3.3   \n",
      "3        5  Father of the Bride Part II (1995)             3.1   \n",
      "4        7                      Sabrina (1995)             3.2   \n",
      "\n",
      "                                      feature_vector  \n",
      "0  [-0.042944200336933136, -0.009570187889039516,...  \n",
      "1  [-0.0005739312618970871, 0.024589821696281433,...  \n",
      "2  [0.032066673040390015, -0.0006265472620725632,...  \n",
      "3  [-0.013254916295409203, 0.037702854722738266, ...  \n",
      "4  [-0.01430355291813612, 0.03986180201172829, 0....  \n"
     ]
    }
   ],
   "source": [
    "filtered_data_copy = filtered_data.copy()\n",
    "\n",
    "# What we used before\n",
    "filtered_data['feature_vector'] = filtered_data.apply(create_feature_vector, axis=1)\n",
    "\n",
    "# What we are using now\n",
    "movies_df['feature_vector'] = movies_df.apply(\n",
    "    lambda row: np.concatenate([row['tag_vector'], row['genre_vector']]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "filtered_data1 = filtered_data_copy.merge(\n",
    "    movies_df[['movieId', 'feature_vector']],  # Select only necessary columns\n",
    "    on='movieId',  # Merge on the 'movieId' column\n",
    "    how='left'  # Use a left join to keep all rows in filtered_data_df\n",
    ")\n",
    "\n",
    "#Okay so I mixed the tag vector and the genre vectors into one feature vector\n",
    "#I am going to drop the original tag vector and the genres\n",
    "filtered_data = filtered_data.drop(columns=list(unique_genres))\n",
    "filtered_data = filtered_data.drop(columns='tag')\n",
    "\n",
    "filtered_data1 = filtered_data1.drop(columns=list(unique_genres))\n",
    "filtered_data1 = filtered_data1.drop(columns='tag')\n",
    "\n",
    "print(len(filtered_data1['feature_vector'][6]))\n",
    "print(filtered_data1.head())\n",
    "filtered_data1.to_csv('filtered_movies.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query is the movie we want to isolate\n",
    "#Cosine Similarities\n",
    "def knn_recommendation_cos(query,train_data, user_watched_movies, k=5):\n",
    "    #Extract ratings and feature vectors from training set\n",
    "    #Ratings are optional if you don't want them, I have them here to use as bias\n",
    "    train_features = np.array(train_data['feature_vector'].tolist())\n",
    "    train_ratings = train_data['average_rating'].values#Optional\n",
    "\n",
    "    #kNN using cosine_similarity\n",
    "    similarities = cosine_similarity([query],train_features).flatten()\n",
    "\n",
    "    #Optional Bias\n",
    "    weighted_similarities = similarities * train_ratings\n",
    "\n",
    "    # #get the indicies of nearest movies (5)\n",
    "    # kNN_indices = np.argsort(weighted_similarities)[-k:][::-1] #Sorted by weighted similariy in descending order\n",
    "\n",
    "    # #Get the movies from the index\n",
    "    # kNN_movies = train_data.iloc[kNN_indices]\n",
    "        # Get the indices of nearest movies (more than k initially)\n",
    "    kNN_indices = np.argsort(weighted_similarities)[-k*2:][::-1]  # Get twice the number of recommendations (more than needed)\n",
    "\n",
    "    # Get the movies from the index\n",
    "    kNN_movies = train_data.iloc[kNN_indices]\n",
    "\n",
    "    # Remove the movies the user has already watched\n",
    "    kNN_movies_filtered = kNN_movies[~kNN_movies['movieId'].isin(user_watched_movies)]\n",
    "\n",
    "    # If we have fewer than k movies after filtering, fetch more from the remaining pool\n",
    "    if len(kNN_movies_filtered) < k:\n",
    "        # Find additional movies (not already recommended) by getting the remaining top recommendations\n",
    "        remaining_movies = kNN_movies[~kNN_movies['movieId'].isin(kNN_movies_filtered['movieId'])]\n",
    "        additional_movies_needed = k - len(kNN_movies_filtered)\n",
    "        additional_movies = remaining_movies.head(additional_movies_needed)\n",
    "        \n",
    "        # Combine the filtered list and additional recommendations\n",
    "        kNN_movies_filtered = pd.concat([kNN_movies_filtered, additional_movies])\n",
    "\n",
    "    return kNN_movies_filtered.head(k)  # Ensure we return exactly k recommendations\n",
    "    # return kNN_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to compare cosine to euclidean distance\n",
    "def knn_recommendation_eucl(query,train_data,user_watched_movies,k=5):\n",
    "    #Extract ratings and feature vectors from training set\n",
    "    #Ratings are optional if you don't want them, I have them here to use as bias\n",
    "    train_features = np.array(train_data['feature_vector'].tolist())\n",
    "    train_ratings = train_data['average_rating'].values#Optional\n",
    "\n",
    "    #kNN using euclidean distances\n",
    "    distances = euclidean_distances([query],train_features).flatten()\n",
    "\n",
    "    #Optional Bias\n",
    "    weighted_distances= distances / train_ratings\n",
    "\n",
    "    #get the indicies of nearest movies (5)\n",
    "    # kNN_indices = np.argsort(weighted_distances)[:k] #Sorted by weighted distances ascending order\n",
    "    kNN_indices = np.argsort(weighted_distances)[-k*2:][::-1]  # Get twice the number of recommendations (more than needed)\n",
    "\n",
    "    # Get the movies from the index\n",
    "    kNN_movies = train_data.iloc[kNN_indices]\n",
    "\n",
    "    # Remove the movies the user has already watched\n",
    "    kNN_movies_filtered = kNN_movies[~kNN_movies['movieId'].isin(user_watched_movies)]\n",
    "\n",
    "    # If we have fewer than k movies after filtering, fetch more from the remaining pool\n",
    "    if len(kNN_movies_filtered) < k:\n",
    "        # Find additional movies (not already recommended) by getting the remaining top recommendations\n",
    "        remaining_movies = kNN_movies[~kNN_movies['movieId'].isin(kNN_movies_filtered['movieId'])]\n",
    "        additional_movies_needed = k - len(kNN_movies_filtered)\n",
    "        additional_movies = remaining_movies.head(additional_movies_needed)\n",
    "        \n",
    "        # Combine the filtered list and additional recommendations\n",
    "        kNN_movies_filtered = pd.concat([kNN_movies_filtered, additional_movies])\n",
    "\n",
    "    return kNN_movies_filtered.head(k)  # Ensure we return exactly k recommendations\n",
    "    #Get the movies from the index\n",
    "    # kNN_movies = train_data.iloc[kNN_indices]\n",
    "    # return kNN_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_knn(test_data,train_data,user_watched_movies, k=5):\n",
    "    # Dictionary to store movie frequencies\n",
    "    movie_frequency = {}\n",
    "\n",
    "    for _,row in test_data.iterrows():\n",
    "        query = np.array(row['feature_vector'])\n",
    "        knn_movies = knn_recommendation_cos(query,train_data,user_watched_movies,k)\n",
    "        # print(f\"Current Movie searched: {row['title']}\")\n",
    "        # print(\"Recommended Movies: \")\n",
    "        # print(knn_movies[['title','average_rating']])\n",
    "        # print()\n",
    "\n",
    "        # Update the frequency dictionary\n",
    "        for _, movie_row in knn_movies.iterrows():\n",
    "            movie_title = movie_row['title']\n",
    "            movie_id = movie_row['movieId']\n",
    "            if movie_title in movie_frequency:\n",
    "                movie_frequency[movie_title][0] += 1\n",
    "            else:\n",
    "                movie_frequency[movie_title] = [1, movie_id]\n",
    "\n",
    "    # Sort the movie_frequency dictionary by frequency (the first element of the list)\n",
    "    sorted_dict = dict(sorted(movie_frequency.items(), key=lambda item: item[1][0], reverse=True))\n",
    "\n",
    "    # Get the movie with the maximum frequency\n",
    "    max_key = max(movie_frequency, key=lambda k: movie_frequency[k][0])  # Get the movie with the highest frequency\n",
    "    max_value = movie_frequency[max_key]  # The value is a list: [frequency, movie_id]\n",
    "\n",
    "    print(f\"Maximum value: {max_value[0]} with Key: {max_key} and Movie ID: {max_value[1]}\")\n",
    "\n",
    "    # Print the top 5 recommended movies\n",
    "    count = 0\n",
    "    movieIds = []\n",
    "    for movie, freq in sorted_dict.items():\n",
    "        print(f\"{movie}: Frequency = {freq[0]}, Movie ID = {freq[1]}\")  # Display frequency and Movie ID\n",
    "        movieIds.append(freq[1])\n",
    "        if count == 5:\n",
    "            break\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "    \n",
    "    return movieIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_knn_eucl(test_data,train_data,user_watched_movies, k=5):\n",
    "    # Dictionary to store movie frequencies\n",
    "    movie_frequency = {}\n",
    "\n",
    "    for _,row in test_data.iterrows():\n",
    "        query = np.array(row['feature_vector'])\n",
    "        knn_movies = knn_recommendation_eucl(query,train_data,user_watched_movies,k)\n",
    "        # print(f\"Current Movie searched: {row['title']}\")\n",
    "        # print(\"Recommended Movies: \")\n",
    "        # print(knn_movies[['title','average_rating']])\n",
    "        # print()\n",
    "\n",
    "        # Update the frequency dictionary\n",
    "        for _, movie_row in knn_movies.iterrows():\n",
    "            movie_title = movie_row['title']\n",
    "            movie_id = movie_row['movieId']\n",
    "            if movie_title in movie_frequency:\n",
    "                movie_frequency[movie_title][0] += 1\n",
    "            else:\n",
    "                movie_frequency[movie_title] = [1, movie_id]\n",
    "\n",
    "    # Sort the movie_frequency dictionary by frequency (the first element of the list)\n",
    "    sorted_dict = dict(sorted(movie_frequency.items(), key=lambda item: item[1][0], reverse=True))\n",
    "\n",
    "    # Get the movie with the maximum frequency\n",
    "    max_key = max(movie_frequency, key=lambda k: movie_frequency[k][0])  # Get the movie with the highest frequency\n",
    "    max_value = movie_frequency[max_key]  # The value is a list: [frequency, movie_id]\n",
    "\n",
    "    print(f\"Maximum value: {max_value[0]} with Key: {max_key} and Movie ID: {max_value[1]}\")\n",
    "\n",
    "    # Print the top 5 recommended movies\n",
    "    count = 0\n",
    "    movieIds = []\n",
    "    for movie, freq in sorted_dict.items():\n",
    "        print(f\"{movie}: Frequency = {freq[0]}, Movie ID = {freq[1]}\")  # Display frequency and Movie ID\n",
    "        movieIds.append(freq[1])\n",
    "        if count == 5:\n",
    "            break\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "    \n",
    "    return movieIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(movie_id_1, movie_id_2, train_data):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two movies based on their feature vectors.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the feature vectors for the two movies\n",
    "    movie_1_vector = train_data.loc[train_data['movieId'] == movie_id_1, 'feature_vector'].values[0]\n",
    "    # print(movie_1_vector)\n",
    "    movie_2_vector = train_data.loc[train_data['movieId'] == movie_id_2, 'feature_vector'].values[0]\n",
    "\n",
    "    # Reshape the vectors to 2D arrays (required for cosine_similarity)\n",
    "    movie_1_vector = movie_1_vector.reshape(1, -1)\n",
    "    movie_2_vector = movie_2_vector.reshape(1, -1)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(movie_1_vector, movie_2_vector)[0][0]\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def calculate_euclidean_distance(movie_id_1, movie_id_2, train_data):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two movies based on their feature vectors.\n",
    "\n",
    "    Args:\n",
    "        movie_id_1 (int): The ID of the first movie.\n",
    "        movie_id_2 (int): The ID of the second movie.\n",
    "        train_data (DataFrame): The DataFrame containing movie data with a 'feature_vector' column.\n",
    "\n",
    "    Returns:\n",
    "        float: The Euclidean distance between the two movies' feature vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the feature vectors for the two movies\n",
    "    movie_1_vector = train_data.loc[train_data['movieId'] == movie_id_1, 'feature_vector'].values[0]\n",
    "    movie_2_vector = train_data.loc[train_data['movieId'] == movie_id_2, 'feature_vector'].values[0]\n",
    "\n",
    "    # Calculate Euclidean distance\n",
    "    distance = euclidean(movie_1_vector, movie_2_vector)\n",
    "\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(df, filt_data, n=7):\n",
    "    # Create empty lists to store train and test data\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # Group by 'userID' to process each user individually\n",
    "    \n",
    "    merged_df = pd.merge(df, filt_data, on='movieId')\n",
    "    grouped = merged_df.groupby('userId')\n",
    "\n",
    "    for user, group in grouped:\n",
    "        # Sort movies by rating in descending order\n",
    "        sorted_group = group.sort_values(by='rating', ascending=False)\n",
    "        \n",
    "        # Select the top n rated movies for testing\n",
    "        test = sorted_group.head(n)\n",
    "        \n",
    "        # Use the rest for training\n",
    "        train = sorted_group.iloc[n:]\n",
    "        \n",
    "        # Append to respective lists\n",
    "        test_list.append(test)\n",
    "        train_list.append(train)\n",
    "\n",
    "    # Combine all train and test splits into DataFrames\n",
    "    train_data = pd.concat(train_list).reset_index(drop=True)\n",
    "    test_data = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    print(\"Training Data:\")\n",
    "    print(train_data)\n",
    "    print(\"\\nTesting Data:\")\n",
    "    print(test_data)\n",
    "    print(type(train_data))\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "       userId  movieId  rating   timestamp  \\\n",
      "0           1     1240     5.0   964983723   \n",
      "1           1     2139     5.0   964982791   \n",
      "2           1     2115     5.0   964982529   \n",
      "3           1     2078     5.0   964982838   \n",
      "4           1     2058     5.0   964982400   \n",
      "...       ...      ...     ...         ...   \n",
      "48282     610    96861     2.0  1493850474   \n",
      "48283     610    69526     2.0  1493846153   \n",
      "48284     610     6541     1.5  1493845480   \n",
      "48285     610   120635     1.0  1493850489   \n",
      "48286     610    68319     1.0  1493845505   \n",
      "\n",
      "                                                   title  average_rating  \\\n",
      "0                                 Terminator, The (1984)             3.9   \n",
      "1                             Secret of NIMH, The (1982)             3.5   \n",
      "2            Indiana Jones and the Temple of Doom (1984)             3.6   \n",
      "3                                Jungle Book, The (1967)             3.8   \n",
      "4                                 Negotiator, The (1998)             3.4   \n",
      "...                                                  ...             ...   \n",
      "48282                                     Taken 2 (2012)             3.3   \n",
      "48283         Transformers: Revenge of the Fallen (2009)             2.4   \n",
      "48284  League of Extraordinary Gentlemen, The (a.k.a....             2.6   \n",
      "48285                                     Taken 3 (2015)             2.7   \n",
      "48286                    X-Men Origins: Wolverine (2009)             2.9   \n",
      "\n",
      "                                          feature_vector  \n",
      "0      [0.09726841002702713, -0.07475874572992325, -0...  \n",
      "1      [0.07489033043384552, -0.08546503633260727, 0....  \n",
      "2      [-0.034710951149463654, 0.017216186970472336, ...  \n",
      "3      [0.07349581271409988, 0.05029662325978279, 0.0...  \n",
      "4      [-0.05047808215022087, -0.06758777797222137, -...  \n",
      "...                                                  ...  \n",
      "48282  [-0.024538569152355194, -0.05947592481970787, ...  \n",
      "48283  [0.09924023598432541, 0.08376741409301758, -0....  \n",
      "48284  [0.07344192266464233, 0.07700993865728378, 0.0...  \n",
      "48285  [0.030864253640174866, -0.005395594518631697, ...  \n",
      "48286  [0.08694885671138763, 0.0674978569149971, 0.03...  \n",
      "\n",
      "[48287 rows x 7 columns]\n",
      "\n",
      "Testing Data:\n",
      "Empty DataFrame\n",
      "Columns: [userId, movieId, rating, timestamp, title, average_rating, feature_vector]\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Training Data:\n",
      "       userId  movieId  rating   timestamp  \\\n",
      "0           1     1240     5.0   964983723   \n",
      "1           1     2139     5.0   964982791   \n",
      "2           1     2115     5.0   964982529   \n",
      "3           1     2078     5.0   964982838   \n",
      "4           1     2058     5.0   964982400   \n",
      "...       ...      ...     ...         ...   \n",
      "48282     610    96861     2.0  1493850474   \n",
      "48283     610    69526     2.0  1493846153   \n",
      "48284     610     6541     1.5  1493845480   \n",
      "48285     610   120635     1.0  1493850489   \n",
      "48286     610    68319     1.0  1493845505   \n",
      "\n",
      "                                                   title  average_rating  \\\n",
      "0                                 Terminator, The (1984)             3.9   \n",
      "1                             Secret of NIMH, The (1982)             3.5   \n",
      "2            Indiana Jones and the Temple of Doom (1984)             3.6   \n",
      "3                                Jungle Book, The (1967)             3.8   \n",
      "4                                 Negotiator, The (1998)             3.4   \n",
      "...                                                  ...             ...   \n",
      "48282                                     Taken 2 (2012)             3.3   \n",
      "48283         Transformers: Revenge of the Fallen (2009)             2.4   \n",
      "48284  League of Extraordinary Gentlemen, The (a.k.a....             2.6   \n",
      "48285                                     Taken 3 (2015)             2.7   \n",
      "48286                    X-Men Origins: Wolverine (2009)             2.9   \n",
      "\n",
      "                                          feature_vector  \n",
      "0      [-0.0036613866686820984, -0.005033273715525865...  \n",
      "1      [-0.045407820492982864, -0.02585730515420437, ...  \n",
      "2      [-0.03983907401561737, 0.03279533237218857, 0....  \n",
      "3      [-0.04789775237441063, 0.025119725614786148, -...  \n",
      "4      [0.04190037027001381, -0.023309800773859024, -...  \n",
      "...                                                  ...  \n",
      "48282  [-0.013856574892997742, 0.010954679921269417, ...  \n",
      "48283  [0.0007363744080066681, 0.01406662818044424, -...  \n",
      "48284  [0.0071102590300142765, 0.009169081225991249, ...  \n",
      "48285  [0.006218317896127701, -0.0122670354321599, -0...  \n",
      "48286  [0.006262298673391342, 0.02877606451511383, -0...  \n",
      "\n",
      "[48287 rows x 7 columns]\n",
      "\n",
      "Testing Data:\n",
      "Empty DataFrame\n",
      "Columns: [userId, movieId, rating, timestamp, title, average_rating, feature_vector]\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "traing_data query50\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = my_train_test_split(rate, filtered_data,n=0)\n",
    "train_data1, test_data1 = my_train_test_split(rate, filtered_data1,n=0)\n",
    "\n",
    "print(f\"traing_data query{len(train_data['feature_vector'][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for that specific user\n",
    "# print(type(train_data))\n",
    "# print(train_data)\n",
    "user_id = 10\n",
    "user_data = train_data[train_data['userId'] == user_id]\n",
    "user_data1 = train_data1[train_data1['userId'] == user_id]\n",
    "# user_data1 = test_data[test_data['userId'] == 2]\n",
    "# print(user_data)\n",
    "# print(user_data1)\n",
    "\n",
    "# test_knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value: 7 with Key: Lady Jane (1986) and Movie ID: 6201\n",
      "Lady Jane (1986): Frequency = 7, Movie ID = 6201\n",
      "Wedding Banquet, The (Xi yan) (1993): Frequency = 7, Movie ID = 7023\n",
      "Philadelphia Story, The (1940): Frequency = 7, Movie ID = 898\n",
      "Harold and Maude (1971): Frequency = 7, Movie ID = 1235\n",
      "Roman Holiday (1953): Frequency = 7, Movie ID = 916\n",
      "Manhattan (1979): Frequency = 5, Movie ID = 1244\n",
      "\n",
      " ---------- Next old Filter --------- \n",
      "\n",
      "Maximum value: 7 with Key: Lady Jane (1986) and Movie ID: 6201\n",
      "Lady Jane (1986): Frequency = 7, Movie ID = 6201\n",
      "Wedding Banquet, The (Xi yan) (1993): Frequency = 7, Movie ID = 7023\n",
      "Philadelphia Story, The (1940): Frequency = 7, Movie ID = 898\n",
      "Harold and Maude (1971): Frequency = 7, Movie ID = 1235\n",
      "Cyrano de Bergerac (1990): Frequency = 7, Movie ID = 1277\n",
      "84 Charing Cross Road (1987): Frequency = 5, Movie ID = 5404\n",
      "\n",
      " ---------- Test with Eucl --------- \n",
      "\n",
      "Maximum value: 47 with Key: Begotten (1990) and Movie ID: 26717\n",
      "Begotten (1990): Frequency = 47, Movie ID = 26717\n",
      "My Demon Lover (1987): Frequency = 45, Movie ID = 4138\n",
      "Losin' It (1983): Frequency = 41, Movie ID = 4204\n",
      "Jaws 3-D (1983): Frequency = 38, Movie ID = 1389\n",
      "Poltergeist II: The Other Side (1986): Frequency = 28, Movie ID = 1995\n",
      "Oh, God! Book II (1980): Frequency = 17, Movie ID = 5213\n"
     ]
    }
   ],
   "source": [
    "user_watched_movies = user_data['movieId'].to_numpy()\n",
    "# print(user_watched_movies)\n",
    "# you can use either filtered_data1(new vect) or filtered_data(old vect)\n",
    "movieIDs1 = test_knn(user_data1, filtered_data1, user_watched_movies, k=5)\n",
    "\n",
    "print(\"\\n ---------- Next old Filter --------- \\n\")\n",
    "\n",
    "movieIDs = test_knn(user_data, filtered_data, user_watched_movies, k=5)\n",
    "\n",
    "print(\"\\n ---------- Test with Eucl --------- \\n\")\n",
    "movieIDs2 = test_knn_eucl(user_data1, filtered_data1, user_watched_movies, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "Recommended movie: 6201 Similarity:0.39839186836495644\n",
      "Recommended movie: 7023 Similarity:0.4806223190589474\n",
      "Recommended movie: 898 Similarity:0.480669132888907\n",
      "Recommended movie: 1235 Similarity:0.48013425250717184\n",
      "Recommended movie: 916 Similarity:0.4813185625001533\n",
      "Recommended movie: 1244 Similarity:0.48060386340138744\n"
     ]
    }
   ],
   "source": [
    "# Gets the mean of the cosine_similarity between \n",
    "# the user movies and each recommended movies\n",
    "\n",
    "user_test_movies = user_data1['movieId'].to_numpy()\n",
    "print(len(user_test_movies))\n",
    "arr = []\n",
    "\n",
    "for x in movieIDs1:\n",
    "    arr = []\n",
    "    for y in user_test_movies:\n",
    "        z = calculate_cosine_similarity(x, y, filtered_data1)\n",
    "        arr.append(z)\n",
    "\n",
    "    print(f\"Recommended movie: {x} Similarity:{np.mean(arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "Recommended movie: 6201 Similarity:0.3923577293777858\n",
      "Recommended movie: 7023 Similarity:0.47776737176586076\n",
      "Recommended movie: 898 Similarity:0.4762643815790968\n",
      "Recommended movie: 1235 Similarity:0.475092014034493\n",
      "Recommended movie: 1277 Similarity:0.47776737176586076\n",
      "Recommended movie: 5404 Similarity:0.3929433887821629\n"
     ]
    }
   ],
   "source": [
    "user_test_movies = user_data['movieId'].to_numpy()\n",
    "print(len(user_test_movies))\n",
    "arr = []\n",
    "\n",
    "for x in movieIDs:\n",
    "    arr = []\n",
    "    for y in user_test_movies:\n",
    "        z = calculate_cosine_similarity(x, y, filtered_data)\n",
    "        arr.append(z)\n",
    "\n",
    "    print(f\"Recommended movie: {x} Similarity:{np.mean(arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "Recommended movie: 26717 Distance:1.9399781169431087\n",
      "Recommended movie: 4138 Distance:2.0053436033735355\n",
      "Recommended movie: 4204 Distance:1.7207408841173932\n",
      "Recommended movie: 1389 Distance:2.1163123216192528\n",
      "Recommended movie: 1995 Distance:2.1718821824424297\n",
      "Recommended movie: 5213 Distance:1.7200561993144474\n"
     ]
    }
   ],
   "source": [
    "user_test_movies = user_data1['movieId'].to_numpy()\n",
    "print(len(user_test_movies))\n",
    "arr = []\n",
    "\n",
    "for x in movieIDs2:\n",
    "    arr = []\n",
    "    for y in user_test_movies:\n",
    "        z = calculate_euclidean_distance(x, y, filtered_data1)\n",
    "        arr.append(z)\n",
    "\n",
    "    print(f\"Recommended movie: {x} Distance:{np.mean(arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Precision: 0.76\n",
      "Recall: 1.00\n",
      "True Positives: 204\n",
      "False Positives: 66\n",
      "True Negatives: 0\n",
      "False Negatives: 0\n"
     ]
    }
   ],
   "source": [
    "def evaluate_recommendations(user_data, recommended_movie_ids, filtered_data, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Evaluates recommendation accuracy using cosine similarity and user ratings.\n",
    "    For movies that have a rating of 4 or 5 by the user we will want our \n",
    "    recommendation to have a cosine_similarity between recommended and that \n",
    "    movie, to be above the cosine_similarity threshold we defined. if we have a \n",
    "    user rated movie below 2, but we have a the cosine_similarity above the \n",
    "    threshold that will be our false positive.\n",
    "\n",
    "    Args:\n",
    "        user_data (DataFrame): Data for a single user, with columns 'movieId' and 'rating'.\n",
    "        recommended_movie_ids (list): List of movieIds recommended to the user.\n",
    "        filtered_data (DataFrame): Full dataset with feature vectors for movies.\n",
    "        similarity_threshold (float): The cosine similarity threshold.\n",
    "\n",
    "    Returns:\n",
    "        dict: Accuracy, precision, recall, and other metrics.\n",
    "    \"\"\"\n",
    "    # User's watched movies and their ratings\n",
    "    user_test_movies = user_data['movieId'].to_numpy()\n",
    "    user_ratings = user_data.set_index('movieId')['rating'].to_dict()\n",
    "\n",
    "    # Initialize metrics\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for recommended_movie in recommended_movie_ids:\n",
    "        # Calculate similarities for all user test movies\n",
    "        similarities = [\n",
    "            calculate_cosine_similarity(recommended_movie, test_movie, filtered_data)\n",
    "            for test_movie in user_test_movies\n",
    "        ]\n",
    "\n",
    "        # Use the mean similarity for this recommendation\n",
    "        mean_similarity = np.mean(similarities)\n",
    "\n",
    "        # Check if the recommended movie is similar above the threshold\n",
    "        is_similar = mean_similarity >= similarity_threshold\n",
    "\n",
    "        # Determine if this is TP, FP, TN, or FN\n",
    "        for test_movie in user_test_movies:\n",
    "            user_rating = user_ratings[test_movie]\n",
    "\n",
    "            if user_rating >= 3:  # User likes the movie\n",
    "                if is_similar:\n",
    "                    true_positives += 1\n",
    "                else:\n",
    "                    false_negatives += 1\n",
    "            elif user_rating <= 2:  # User dislikes the movie\n",
    "                if is_similar:\n",
    "                    false_positives += 1\n",
    "                else:\n",
    "                    true_negatives += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    total = true_positives + false_positives + true_negatives + false_negatives\n",
    "    accuracy = (true_positives + true_negatives) / total if total > 0 else 0\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"true_positives\": true_positives,\n",
    "        \"false_positives\": false_positives,\n",
    "        \"true_negatives\": true_negatives,\n",
    "        \"false_negatives\": false_negatives,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "user_test_movies = user_data1['movieId'].to_numpy()\n",
    "recommended_movie_ids = movieIDs1  # Replace with your list of recommended movies\n",
    "similarity_threshold = 0.35\n",
    "\n",
    "metrics = evaluate_recommendations(user_data1, recommended_movie_ids, filtered_data1, similarity_threshold)\n",
    "\n",
    "print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "print(f\"True Positives: {metrics['true_positives']}\")\n",
    "print(f\"False Positives: {metrics['false_positives']}\")\n",
    "print(f\"True Negatives: {metrics['true_negatives']}\")\n",
    "print(f\"False Negatives: {metrics['false_negatives']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.003223528191637"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_euclidean_distance(29, 32, filtered_data1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
